{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinSurvival Competition: Starter Notebook (XGBoost Cox Model Prediction Submission)\n",
    "\n",
    "**Objective:** This notebook provides a workflow for creating a valid prediction submission using the XGBoost Cox survival model. The competition requires you to submit a `.zip` file containing 16 separate prediction files in CSV format.\n",
    "\n",
    "This notebook will guide you through:\n",
    "1.  Loading the training and test sets for each of the 16 tasks from a single directory.\n",
    "2.  Training a model (using XGBoost Cox model as an example).\n",
    "3.  Generating predictions on the test set in the required format.\n",
    "4.  Saving each set of predictions to a correctly named CSV file.\n",
    "5.  Zipping all 16 prediction files for submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "# Install required packages\n",
    "# pip install -q pandas xgboost scikit-learn numpy\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define a Preprocessing Function\n",
    "\n",
    "Even though you are not submitting this code, you will still need a preprocessing pipeline to train your models effectively. You can use the one below as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    train_df_with_labels: pd.DataFrame,\n",
    "    test_features_df: Optional[pd.DataFrame] = None,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Preprocesses data for the competition.\n",
    "    \"\"\"\n",
    "    train_targets = train_df_with_labels[[\"timeDiff\", \"status\"]]\n",
    "    train_features = train_df_with_labels.drop(columns=[\"timeDiff\", \"status\"])\n",
    "    cols_to_drop = [\"id\", \"user\", \"pool\", \"Index Event\", \"Outcome Event\", \"type\", \"timestamp\"]\n",
    "    train_features = train_features.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "    categorical_cols = train_features.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    for col in categorical_cols:\n",
    "        top_categories = train_features[col].value_counts().nlargest(10).index\n",
    "        train_features[col] = train_features[col].where(train_features[col].isin(top_categories), \"Other\")\n",
    "    train_features_encoded = pd.get_dummies(train_features, columns=categorical_cols, dummy_na=True, drop_first=True)\n",
    "    numerical_cols = train_features_encoded.select_dtypes(include=np.number).columns\n",
    "    scaler = StandardScaler()\n",
    "    train_features_scaled = scaler.fit_transform(train_features_encoded[numerical_cols])\n",
    "    train_features_final = pd.DataFrame(train_features_scaled, index=train_features_encoded.index, columns=numerical_cols).fillna(0)\n",
    "    cols_to_keep = train_features_final.columns[train_features_final.var() != 0]\n",
    "    train_features_final = train_features_final[cols_to_keep]\n",
    "    test_processed_features = None\n",
    "    if test_features_df is not None:\n",
    "        test_features = test_features_df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "        for col in categorical_cols:\n",
    "            top_categories = train_features[col].value_counts().nlargest(10).index\n",
    "            test_features[col] = test_features[col].where(test_features[col].isin(top_categories), \"Other\")\n",
    "        test_features_encoded = pd.get_dummies(test_features, columns=categorical_cols, dummy_na=True, drop_first=True)\n",
    "        train_cols = train_features_encoded.columns\n",
    "        test_features_aligned = test_features_encoded.reindex(columns=train_cols, fill_value=0)\n",
    "        test_features_scaled = scaler.transform(test_features_aligned[numerical_cols])\n",
    "        test_features_final = pd.DataFrame(test_features_scaled, index=test_features_aligned.index, columns=numerical_cols).fillna(0)\n",
    "        test_processed_features = test_features_final[cols_to_keep]\n",
    "    return train_features_final, train_targets, test_processed_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Loop, Train, and Save Predictions\n",
    "\n",
    "This is the main part of the notebook. We will loop through all 16 tasks. For each task, we will:\n",
    "1. Load the training data and the test features.\n",
    "2. Preprocess both.\n",
    "3. Train a model on the training data.\n",
    "4. Generate predictions on the processed test features.\n",
    "5. Save the predictions to a CSV file with the correct name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Borrow -> Deposit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [06:55:38] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Borrow -> Repay\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [06:56:02] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Borrow -> Withdraw\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [06:56:24] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Borrow -> Liquidated\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [06:56:46] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Deposit -> Borrow\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [06:57:46] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Deposit -> Repay\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [06:58:26] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Deposit -> Withdraw\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [06:59:05] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Deposit -> Liquidated\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [06:59:44] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Repay -> Borrow\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [07:00:01] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Repay -> Deposit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [07:00:23] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Repay -> Withdraw\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [07:00:44] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Repay -> Liquidated\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [07:01:05] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Withdraw -> Borrow\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [07:01:36] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Withdraw -> Deposit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [07:02:03] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Withdraw -> Repay\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [07:02:34] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for: Withdraw -> Liquidated\n",
      "==================================================\n",
      "\n",
      "\n",
      "All prediction files have been generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1699063/1793650866.py:52: UserWarning: [07:03:06] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.get_booster().save_model(modelPath)\n"
     ]
    }
   ],
   "source": [
    "# Define path to the single participant data folder.\n",
    "DATA_PATH = \"./data/\"\n",
    "CACHE_DIR = \"./cache/\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_model_for_pair_and_date(\n",
    "    index_event: str, outcome_event: str, model_date: str = None\n",
    ") -> str:\n",
    "    model_filename = f\"xgboost_cox_{index_event}_{outcome_event}_{model_date}.model\"\n",
    "    model_path = os.path.join(CACHE_DIR, model_filename)\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        return model.load_model(model_path)\n",
    "\n",
    "    dataset_path = os.path.join(index_event, outcome_event)\n",
    "\n",
    "    # --- Load and Preprocess ---\n",
    "    train_df = pd.read_csv(os.path.join(DATA_PATH, dataset_path, \"data.csv\"))\n",
    "    train_df = (\n",
    "        train_df[train_df[\"timestamp\"] + train_df[\"timeDiff\"] <= model_date]\n",
    "        if model_date\n",
    "        else train_df\n",
    "    )\n",
    "\n",
    "    X_train, y_train, _ = preprocess(train_df)\n",
    "\n",
    "    # --- Train Model ---\n",
    "    # Prepare target variables for Cox regression\n",
    "    y_train_duration = y_train[\"timeDiff\"].values\n",
    "    y_train_event = y_train[\"status\"].values\n",
    "\n",
    "    # Create model with Cox objective\n",
    "    model = XGBRegressor(\n",
    "        objective=\"survival:cox\",\n",
    "        eval_metric=\"cox-nloglik\",\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    # Fit model: XGBoost Cox expects labels to be the event indicators\n",
    "    # and the sample_weight to be the durations\n",
    "    model.fit(X_train, y_train_event, sample_weight=y_train_duration)\n",
    "\n",
    "    # Save model: prefer the sklearn wrapper's save_model, fall back to Booster.save_model\n",
    "    try:\n",
    "        model.save_model(modelPath)\n",
    "    except Exception:\n",
    "        model.get_booster().save_model(modelPath)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define all 16 event pairs\n",
    "index_events = [\"Borrow\", \"Deposit\", \"Repay\", \"Withdraw\"]\n",
    "outcome_events = index_events + [\"Liquidated\"]\n",
    "event_pairs = []\n",
    "for index_event in index_events:\n",
    "    for outcome_event in outcome_events:\n",
    "        if index_event == outcome_event:\n",
    "            continue\n",
    "        event_pairs.append((index_event, outcome_event))\n",
    "\n",
    "for index_event, outcome_event in event_pairs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training for: {index_event} -> {outcome_event}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    get_model_for_pair_and_date(index_event, outcome_event, 1751328000)\n",
    "\n",
    "print(\"\\n\\nAll prediction files have been generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "actionAgent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

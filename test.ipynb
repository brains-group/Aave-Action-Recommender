{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c77fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755726959.0\n"
     ]
    }
   ],
   "source": [
    "import pyreadr\n",
    "transactions_df = pyreadr.read_r(\"/home/spadef/data/IDEA_DeFi_Research/Data/Lending_Protocols/Aave/V3/Polygon/transactionsFinSurvival.rds\")[None]\n",
    "# transactions_df.to_csv(\"/home/spadef/data/IDEA_DeFi_Research/Data/Lending_Protocols/Aave/V3/Polygon/transactionsFinSurvival.csv\", index=False)\n",
    "print(transactions_df[\"timestamp\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74406a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "EVENTS = [\"Deposit\", \"Withdraw\", \"Repay\", \"Borrow\", \"Liquidated\"]\n",
    "DATA_PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4231de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = {}\n",
    "for index_event in EVENTS:\n",
    "    for outcome_event in EVENTS:\n",
    "        csv_path = os.path.join(DATA_PATH, index_event, outcome_event, \"data.csv\")\n",
    "        if not os.path.exists(csv_path):\n",
    "            continue\n",
    "        df = pd.read_csv(csv_path)\n",
    "        for _, row in df.iterrows():\n",
    "            if row[\"user\"] not in users:\n",
    "                users[row[\"user\"]] = {\n",
    "                    \"user_address\": \"0xUser123\",\n",
    "                    \"description\": \"My custom user profile\",\n",
    "                    \"transactions\": [],\n",
    "                }\n",
    "            users[row[\"user\"]][\"transactions\"].append(\n",
    "                {\"action\": row[\"\"], \"symbol\": \"USDC\", \"amount\": 5000, \"timestamp\": 0}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9952a589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated ./data/Deposit/Withdraw/data.csv\n"
     ]
    }
   ],
   "source": [
    "for index_event in EVENTS:\n",
    "    for outcome_event in EVENTS:\n",
    "        if not (index_event == \"Deposit\" and outcome_event == \"Withdraw\"):\n",
    "            continue\n",
    "        csv_path = os.path.join(DATA_PATH, index_event, outcome_event, \"data.csv\")\n",
    "        if not os.path.exists(csv_path):\n",
    "            continue\n",
    "        df = pd.read_csv(csv_path)\n",
    "        for col in [\"Index Event\", \"Outcome Event\"]:\n",
    "            if col in df.columns:\n",
    "                mask = df[col].notna()\n",
    "                df.loc[mask, col] = (\n",
    "                    df.loc[mask, col]\n",
    "                    .astype(str)\n",
    "                    .str.replace(\"account liquidated\", \"liquidated\", case=False, regex=False)\n",
    "                    .str.strip()\n",
    "                )\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Updated {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614e5e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated ./data/Deposit/Withdraw/data.csv\n"
     ]
    }
   ],
   "source": [
    "for index_event in EVENTS:\n",
    "    for outcome_event in EVENTS:\n",
    "        if not (index_event == \"Deposit\" and outcome_event == \"Withdraw\"):\n",
    "            continue\n",
    "        csv_path = os.path.join(DATA_PATH, index_event, outcome_event, \"data.csv\")\n",
    "        if not os.path.exists(csv_path):\n",
    "            continue\n",
    "        df = pd.read_csv(csv_path)\n",
    "        for col in [\"Index Event\", \"Outcome Event\"]:\n",
    "            if col in df.columns:\n",
    "                mask = df[col].notna()\n",
    "                df.loc[mask, col] = (\n",
    "                    df.loc[mask, col]\n",
    "                    .astype(str)\n",
    "                    .str.replace(\"liquidation\", \"liquidated\", case=False, regex=False)\n",
    "                    .str.strip()\n",
    "                )\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Updated {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd7becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in EVENTS:\n",
    "    csv_path = os.path.join(DATA_PATH, event, event, \"data.csv\")\n",
    "    if not (event == \"Deposit\" and event == \"Withdraw\"):\n",
    "        continue\n",
    "    if not os.path.exists(csv_path):\n",
    "        continue\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for col in [\"Outcome Event\"]:\n",
    "        if col in df.columns:\n",
    "            mask = df[col].notna()\n",
    "            df.loc[mask, col] = (\n",
    "                df.loc[mask, col]\n",
    "                .astype(str)\n",
    "                .str.replace(event + \"_outcome\", event, case=False, regex=False)\n",
    "                .str.strip()\n",
    "            )\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Updated {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e348324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in EVENTS:\n",
    "    csv_path = os.path.join(DATA_PATH, event, event, \"data.csv\")\n",
    "    if not (event == \"Deposit\" and event == \"Withdraw\"):\n",
    "        continue\n",
    "    if not os.path.exists(csv_path):\n",
    "        continue\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for col in [\"Outcome Event\"]:\n",
    "        if col in df.columns:\n",
    "            mask = df[col].notna()\n",
    "            df.loc[mask, col] = (\n",
    "                df.loc[mask, col]\n",
    "                .astype(str)\n",
    "                .str.replace(event, event.lower(), case=False, regex=False)\n",
    "                .str.strip()\n",
    "            )\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Updated {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0100842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated ./data/Liquidated/Deposit/data.csv\n",
      "Updated ./data/Liquidated/Withdraw/data.csv\n",
      "Updated ./data/Liquidated/Repay/data.csv\n",
      "Updated ./data/Liquidated/Borrow/data.csv\n",
      "Updated ./data/Liquidated/Liquidated/data.csv\n"
     ]
    }
   ],
   "source": [
    "index_event = \"Liquidated\"\n",
    "for outcome_event in EVENTS:\n",
    "    csv_path = os.path.join(DATA_PATH, index_event, outcome_event, \"data.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        continue\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for col in [\"Index Event\", \"Outcome Event\"]:\n",
    "        if col in df.columns:\n",
    "            mask = df[col].notna()\n",
    "            df.loc[mask, col] = (\n",
    "                df.loc[mask, col]\n",
    "                .astype(str)\n",
    "                .str.replace(\"liquidation\", \"liquidated\", case=False, regex=False)\n",
    "                .str.strip()\n",
    "            )\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Updated {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ab60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WETH\n",
      "0xae0cc724fc85cd394435eb4f9ddfd3a8c088b4e2's\"Debt\" before liquidation: ['USDC: 898.7291915312042', 'WETH: -1.6900000000003718e-06']\n",
      "USDC\n",
      "0x0e7b3aea0428137786edf20617670179435c530b's\"Debt\" before liquidation: ['USDC: 0.0', 'WETH: 75.7625662202381']\n",
      "USDC\n",
      "0x97dc47d17ab56c32a4d2da1839e3ff261304e95d's\"Debt\" before liquidation: ['USDC: 7.854323']\n",
      "WETH\n",
      "0x5091d57b4feb57db1da04b51cc5454f371b623a6's\"Debt\" before liquidation: ['USDC: 0.0']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "usersToTest = [\n",
    "    \"0xae0cc724fc85cd394435eb4f9ddfd3a8c088b4e2\",\n",
    "    \"0x0e7b3aea0428137786edf20617670179435c530b\",\n",
    "    \"0x97dc47d17ab56c32a4d2da1839e3ff261304e95d\",\n",
    "    \"0x5091d57b4feb57db1da04b51cc5454f371b623a6\",\n",
    "]\n",
    "\n",
    "for user in usersToTest:\n",
    "    with open(\n",
    "        f\"../data/IDEA_DeFi_Research/Data/CSV/profile-generation/user_{user}.json\"\n",
    "    ) as f:\n",
    "        userTest = json.load(f)\n",
    "\n",
    "    userTransactions = userTest[\"transactions\"]\n",
    "    print(next(\n",
    "            (e for i, e in enumerate(userTransactions) if (e[\"action\"] == \"Liquidated\"))\n",
    "        )['debt_symbol'])\n",
    "    userTransactions = userTransactions[\n",
    "        : next(\n",
    "            (i for i, e in enumerate(userTransactions) if (e[\"action\"] == \"Liquidated\")), -1\n",
    "        )\n",
    "    ]\n",
    "    borrows = defaultdict(int)\n",
    "    repays = defaultdict(int)\n",
    "    for transaction in userTransactions:\n",
    "        if transaction[\"action\"] == \"Borrow\":\n",
    "            borrows[transaction[\"symbol\"]] += transaction[\"amount\"]\n",
    "        elif transaction[\"action\"] == \"Repay\":\n",
    "            repays[transaction[\"symbol\"]] += transaction[\"amount\"]\n",
    "    print(f'{user}\\'s \"Debt\" before liquidation: {[f'{symbol}: {borrows[symbol] - repays[symbol]}' for symbol in borrows.keys()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ed1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0x0000000000000000000000000000000000000001\n",
       "1    0x0000000000000000000000000000000000001010\n",
       "2    0x000000000000000000000000000000000000dead\n",
       "3    0x0000000000085a12481aedb59eb3200332aca597\n",
       "4    0x00000000000a29a0800f6f557ddbbe8249397de7\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('../data/IDEA_DeFi_Research/Data/Lending_Protocols/Aave/V2/Polygon/users.csv') as f:\n",
    "    old_users = pd.read_csv(f)['id']\n",
    "old_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf27bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 365677 users, 308205 users were not among the 1121518 old users.\n"
     ]
    }
   ],
   "source": [
    "with open('./data/users.csv') as f:\n",
    "    users = pd.read_csv(f)['id']\n",
    "new_users = set(users) - set(old_users)\n",
    "print(f'Out of {len(users)} users, {len(new_users)} users were not among the {len(old_users)} old users.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19763351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got liquidated users from ./data/Deposit/Liquidated/data.csv\n",
      "Got liquidated users from ./data/Withdraw/Liquidated/data.csv\n",
      "Got liquidated users from ./data/Repay/Liquidated/data.csv\n",
      "Got liquidated users from ./data/Borrow/Liquidated/data.csv\n",
      "Out of 259775 liquidated users, 204309 liquidated users were not among the 1121518 old users.\n"
     ]
    }
   ],
   "source": [
    "usersWithLiquidation = set()\n",
    "outcome_event = \"Liquidated\"\n",
    "for index_event in EVENTS:\n",
    "    if index_event == outcome_event:\n",
    "        continue\n",
    "    csv_path = os.path.join(DATA_PATH, index_event, outcome_event, \"data.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        continue\n",
    "    df = pd.read_csv(csv_path)\n",
    "    usersWithLiquidation = usersWithLiquidation.union(set(df['user']))\n",
    "    print(f\"Got liquidated users from {csv_path}\")\n",
    "new_liquidated_users = set(usersWithLiquidation) - set(old_users)\n",
    "print(f'Out of {len(usersWithLiquidation)} liquidated users, {len(new_liquidated_users)} liquidated users were not among the {len(old_users)} old users.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d95345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got liquidated users from ./data/Liquidated/Deposit/data.csv\n",
      "Got liquidated users from ./data/Liquidated/Withdraw/data.csv\n",
      "Got liquidated users from ./data/Liquidated/Repay/data.csv\n",
      "Got liquidated users from ./data/Liquidated/Borrow/data.csv\n",
      "Out of 13743 liquidated users, 8899 liquidated users were not among the 1121518 old users.\n"
     ]
    }
   ],
   "source": [
    "usersWithLiquidation = set()\n",
    "index_event = \"Liquidated\"\n",
    "for outcome_event in EVENTS:\n",
    "    if index_event == outcome_event:\n",
    "        continue\n",
    "    csv_path = os.path.join(DATA_PATH, index_event, outcome_event, \"data.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        continue\n",
    "    df = pd.read_csv(csv_path)\n",
    "    usersWithLiquidation = usersWithLiquidation.union(set(df['user']))\n",
    "    print(f\"Got liquidated users from {csv_path}\")\n",
    "new_liquidated_users = set(usersWithLiquidation) - set(old_users)\n",
    "print(f'Out of {len(usersWithLiquidation)} liquidated users, {len(new_liquidated_users)} liquidated users were not among the {len(old_users)} old users.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65f22014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0x97dc47d17ab56c32a4d2da1839e3ff261304e95d',\n",
       " '0x5091d57b4feb57db1da04b51cc5454f371b623a6']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[user for user in usersToTest if user in new_liquidated_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3956641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1328 zero-debt liquidated users, 366 zero-debt liquidated users were not among the 1121518 old users.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./Aave-Simulator/results/zero-debt-liquidation-analysis/analysis_20251218_164135.json') as f:\n",
    "    zero_debt_liquidated_users = [case['user_address'] for case in json.load(f)['zero_debt_cases']]\n",
    "new_zero_liquidated_users = set(zero_debt_liquidated_users) - set(old_users)\n",
    "print(f'Out of {len(zero_debt_liquidated_users)} zero-debt liquidated users, {len(new_zero_liquidated_users)} zero-debt liquidated users were not among the {len(old_users)} old users.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fc1f86",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mactionAgentTraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m verify_amount_feature_effect, get_model_for_pair_and_date\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m model = get_model_for_pair_and_date(\u001b[33m\"\u001b[39m\u001b[33mRepay\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLiquidated\u001b[39m\u001b[33m\"\u001b[39m, pd.to_datetime(\u001b[33m\"\u001b[39m\u001b[33m2024-05-05 15:33:51.800000\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/actionAgent/actionAgentTraining.py:1214\u001b[39m\n\u001b[32m   1209\u001b[39m         logger.info(\u001b[33m\"\u001b[39m\u001b[33mRecommended \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfor \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(recommendations[rowID]), rowID)\n\u001b[32m   1210\u001b[39m     \u001b[38;5;66;03m# with open(recommendation_cache_file, \"wb\") as f:\u001b[39;00m\n\u001b[32m   1211\u001b[39m     \u001b[38;5;66;03m#     pkl.dump(recommendations, f)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1214\u001b[39m \u001b[43mrun_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/actionAgent/actionAgentTraining.py:1205\u001b[39m, in \u001b[36mrun_training_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1203\u001b[39m rowID = \u001b[38;5;28mstr\u001b[39m(row)\n\u001b[32m   1204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rowID \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recommendations:\n\u001b[32m-> \u001b[39m\u001b[32m1205\u001b[39m     recommendations[rowID] = \u001b[43mrecommend_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1206\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m iter_count % \u001b[32m1\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m   1207\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(recommendation_cache_file, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/actionAgent/actionAgentTraining.py:1018\u001b[39m, in \u001b[36mrecommend_action\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m   1009\u001b[39m is_at_risk, most_recent_predictions, _ = determine_liquidation_risk(row)\n\u001b[32m   1011\u001b[39m recommended_action = (\n\u001b[32m   1012\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRepay\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1013\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m most_recent_predictions[\u001b[33m\"\u001b[39m\u001b[33mRepay\u001b[39m\u001b[33m\"\u001b[39m] >= most_recent_predictions[\u001b[33m\"\u001b[39m\u001b[33mDeposit\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1014\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m is_at_risk\n\u001b[32m   1015\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mDeposit\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1016\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1018\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize_recommendation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecommended_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/actionAgent/actionAgentTraining.py:935\u001b[39m, in \u001b[36moptimize_recommendation\u001b[39m\u001b[34m(row, recommended_action)\u001b[39m\n\u001b[32m    932\u001b[39m     logger.exception(\u001b[33m\"\u001b[39m\u001b[33mDEBUG: error preparing single-action prediction\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    934\u001b[39m \u001b[38;5;66;03m# If risk remains, iteratively increase the amount and log single-action predictions\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mdetermine_liquidation_risk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_action\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]:\n\u001b[32m    936\u001b[39m     new_action = generate_next_transaction(\n\u001b[32m    937\u001b[39m         row,\n\u001b[32m    938\u001b[39m         recommended_action,\n\u001b[32m    939\u001b[39m         amount=new_action[\u001b[33m\"\u001b[39m\u001b[33mamount\u001b[39m\u001b[33m\"\u001b[39m] * \u001b[32m2\u001b[39m,\n\u001b[32m    940\u001b[39m     )\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# logger = logging.getLogger(__name__)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/actionAgent/actionAgentTraining.py:716\u001b[39m, in \u001b[36mdetermine_liquidation_risk\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetermine_liquidation_risk\u001b[39m(row: pd.Series):\n\u001b[32m    714\u001b[39m     predict_transaction_history = {\n\u001b[32m    715\u001b[39m         key: value\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget_transaction_history_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m.items()\n\u001b[32m    717\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m value\n\u001b[32m    718\u001b[39m     }\n\u001b[32m    720\u001b[39m     is_at_risk = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    722\u001b[39m     most_recent_predictions = predict_transaction_history[\n\u001b[32m    723\u001b[39m         \u001b[38;5;28mmax\u001b[39m(predict_transaction_history.keys())\n\u001b[32m    724\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/actionAgent/actionAgentTraining.py:505\u001b[39m, in \u001b[36mget_transaction_history_predictions\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m    502\u001b[39m train_dates, test_dates = get_date_ranges()\n\u001b[32m    503\u001b[39m dates = train_dates.union(test_dates)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m user_history = \u001b[43mget_user_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mup_to_timestamp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    507\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m user_history = pd.concat([user_history, row.to_frame().T]).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    510\u001b[39m model_date = dates[dates <= pd.to_datetime(row[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m], unit=\u001b[33m\"\u001b[39m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)].max()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/actionAgent/actionAgentTraining.py:447\u001b[39m, in \u001b[36mget_user_history\u001b[39m\u001b[34m(user_id, up_to_timestamp)\u001b[39m\n\u001b[32m    445\u001b[39m event_path = os.path.join(DATA_PATH, index_event, outcome_event, \u001b[33m\"\u001b[39m\u001b[33mdata.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# use cached loader\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m event_df = \u001b[43mget_event_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_event\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutcome_event\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (event_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    449\u001b[39m     user_events = event_df[\n\u001b[32m    450\u001b[39m         (event_df[\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m] == user_id)\n\u001b[32m    451\u001b[39m         & (event_df[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m] <= up_to_timestamp)\n\u001b[32m    452\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/actionAgent/actionAgentTraining.py:81\u001b[39m, in \u001b[36mget_event_df\u001b[39m\u001b[34m(index_event, outcome_event)\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     83\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWarning: failed to read \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/finsur/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/finsur/lib/python3.13/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/finsur/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/finsur/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:334\u001b[39m, in \u001b[36mgetstate\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from actionAgentTraining import verify_amount_feature_effect, get_model_for_pair_and_date\n",
    "import pandas as pd\n",
    "\n",
    "model = get_model_for_pair_and_date(\"Repay\", \"Liquidated\", pd.to_datetime(\"2024-05-05 15:33:51.800000\"))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca423488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No clipped values found in any _baseline.pkl files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.constants import MODEL_CACHE_DIR\n",
    "import os\n",
    "import pickle\n",
    "import numbers\n",
    "import numpy as np\n",
    "\n",
    "def scan_baseline_clips(print_fn=print, clip_thresholds=None):\n",
    "    \"\"\"Scan all *_baseline.pkl files in `MODEL_CACHE_DIR` and report values equal\n",
    "    to clipping thresholds (by default -50 and 50).\n",
    "\n",
    "    Returns a dict mapping filename -> list of (path, value) where value was equal\n",
    "    to a clipping threshold.\n",
    "    \"\"\"\n",
    "    if clip_thresholds is None:\n",
    "        clip_thresholds = [-50.0, 50.0]\n",
    "\n",
    "    results = {}\n",
    "    for fname in os.listdir(MODEL_CACHE_DIR):\n",
    "        if not fname.endswith(\"_baseline.pkl\"):\n",
    "            continue\n",
    "        full = os.path.join(MODEL_CACHE_DIR, fname)\n",
    "        try:\n",
    "            with open(full, \"rb\") as f:\n",
    "                obj = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print_fn(f\"Failed to load {full}: {e}\")\n",
    "            continue\n",
    "\n",
    "        found = []\n",
    "\n",
    "        def _walk(o, path=\"root\"):\n",
    "            # Numeric scalar\n",
    "            if isinstance(o, numbers.Number):\n",
    "                for t in clip_thresholds:\n",
    "                    try:\n",
    "                        if float(o) == float(t):\n",
    "                            found.append((path, float(o)))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            # numpy arrays\n",
    "            elif isinstance(o, np.ndarray):\n",
    "                for t in clip_thresholds:\n",
    "                    mask = np.isclose(o, t)\n",
    "                    if np.any(mask):\n",
    "                        idxs = np.argwhere(mask)\n",
    "                        for idx in idxs:\n",
    "                            found.append((f\"{path}{tuple(idx.tolist())}\", float(t)))\n",
    "            # list/tuple/set\n",
    "            elif isinstance(o, (list, tuple, set)):\n",
    "                for i, v in enumerate(o):\n",
    "                    _walk(v, f\"{path}[{i}]\")\n",
    "            # dict\n",
    "            elif isinstance(o, dict):\n",
    "                for k, v in o.items():\n",
    "                    _walk(v, f\"{path}.{k}\")\n",
    "            else:\n",
    "                # try to inspect attributes (e.g., objects with __dict__)\n",
    "                if hasattr(o, \"__dict__\"):\n",
    "                    for k, v in vars(o).items():\n",
    "                        _walk(v, f\"{path}.{k}\")\n",
    "\n",
    "        _walk(obj)\n",
    "\n",
    "        if found:\n",
    "            results[full] = found\n",
    "            print_fn(f\"Found clipped values in {full}:\")\n",
    "            for p, v in found:\n",
    "                print_fn(f\"  {p}: {v}\")\n",
    "\n",
    "    if not results:\n",
    "        print_fn(\"No clipped values found in any _baseline.pkl files.\")\n",
    "\n",
    "    return results\n",
    "\n",
    "scan_baseline_clips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a2e314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:04:13<00:00,  1.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>history_count</th>\n",
       "      <th>history_span_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0xcfdaf25cdfd9c68f37ced1408067d032fc9ec68b</td>\n",
       "      <td>1727636330</td>\n",
       "      <td>883</td>\n",
       "      <td>79050596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0x0fb6eb88f429e2912c3117feeaf512fe35d6ad04</td>\n",
       "      <td>1715218763</td>\n",
       "      <td>503204</td>\n",
       "      <td>1552188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0x357aa453a873ef716ea69088c85be4adbda6282e</td>\n",
       "      <td>1719850422</td>\n",
       "      <td>150380</td>\n",
       "      <td>19213983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0x18fbd380ad51a4bcb3a1a8a89107483d10b716c0</td>\n",
       "      <td>1714940836</td>\n",
       "      <td>341801</td>\n",
       "      <td>14907190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0x706add824132b2a17142ed3c613d42e9c2db635f</td>\n",
       "      <td>1703365296</td>\n",
       "      <td>75</td>\n",
       "      <td>4400069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        user   timestamp  \\\n",
       "0      0  0xcfdaf25cdfd9c68f37ced1408067d032fc9ec68b  1727636330   \n",
       "1      1  0x0fb6eb88f429e2912c3117feeaf512fe35d6ad04  1715218763   \n",
       "2      2  0x357aa453a873ef716ea69088c85be4adbda6282e  1719850422   \n",
       "3      3  0x18fbd380ad51a4bcb3a1a8a89107483d10b716c0  1714940836   \n",
       "4      4  0x706add824132b2a17142ed3c613d42e9c2db635f  1703365296   \n",
       "\n",
       "   history_count  history_span_seconds  \n",
       "0            883              79050596  \n",
       "1         503204               1552188  \n",
       "2         150380              19213983  \n",
       "3         341801              14907190  \n",
       "4             75               4400069  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from actionAgentTraining import get_user_history\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_history_lengths(train_csv_path=os.path.join('cache', 'train_set.csv'), save_to=None, max_rows=None, show_progress=True):\n",
    "    \"\"\"Compute, for every transaction in `train_set.csv`, how long the user's\n",
    "    transaction history is up to that transaction timestamp. Returns a DataFrame with:\n",
    "      - user, timestamp, history_count, history_span_seconds\n",
    "    Parameters:\n",
    "      - train_csv_path: path to CSV of training transactions (default 'cache/train_set.csv')\n",
    "      - save_to: optional path to save the output CSV\n",
    "      - max_rows: optional int to limit processing for quick checks\n",
    "      - show_progress: print progress while iterating\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(train_csv_path)\n",
    "    if max_rows is not None:\n",
    "        df = df.head(max_rows)\n",
    "\n",
    "    rows = []\n",
    "    total = len(df)\n",
    "    for i, row in tqdm(df.iterrows(), total=total, disable=not show_progress):\n",
    "        user = row.get('user') if 'user' in row.index else row.get('User')\n",
    "        ts = int(row.get('timestamp') if 'timestamp' in row.index else row.get('Timestamp'))\n",
    "        try:\n",
    "            hist = get_user_history(user, ts)\n",
    "        except Exception as e:\n",
    "            hist = None\n",
    "        count = 0\n",
    "        span = 0\n",
    "        if isinstance(hist, pd.DataFrame) and not hist.empty:\n",
    "            count = len(hist)\n",
    "            if 'timestamp' in hist.columns:\n",
    "                try:\n",
    "                    earliest = int(hist['timestamp'].min())\n",
    "                    span = ts - earliest\n",
    "                except Exception:\n",
    "                    span = None\n",
    "            else:\n",
    "                span = None\n",
    "        rows.append({'index': i, 'user': user, 'timestamp': ts, 'history_count': count, 'history_span_seconds': span})\n",
    "        # if show_progress and (i % 1000 == 0):\n",
    "        #     print(f'Processed {i+1}/{total} transactions')\n",
    "\n",
    "    res = pd.DataFrame(rows)\n",
    "    if save_to is not None:\n",
    "        res.to_csv(save_to, index=False)\n",
    "    return res\n",
    "\n",
    "# Example: run over full train set and save summary to cache/history_lengths.csv\n",
    "# Uncomment to execute:\n",
    "out = compute_history_lengths()\n",
    "out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c834f8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>history_count</th>\n",
       "      <th>history_span_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0x90eaa542a9575358b24bd7f5b8721989298c546a</td>\n",
       "      <td>1694019124</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0x491919bcf7704fb4c328dd84affd2ad8eca5fd6a</td>\n",
       "      <td>1697124486</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>0x3f5282adca3b9bc02d385e539ad0e66ee7f65fce</td>\n",
       "      <td>1691929436</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0x309a33959bd2cda19473110db175e6a8595cae4b</td>\n",
       "      <td>1701253162</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>0x111111cab58e134a2e3ecd8d3fb72488cf01fefa</td>\n",
       "      <td>1691318969</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>0xe964182ebe3aeb55fed219a07a6e3f38a59c1339</td>\n",
       "      <td>1692185020</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>0x54faad784c3addef84adecaa5ee30d3ed9abcf20</td>\n",
       "      <td>1717535235</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>0xa2a833e55401aab11ddf0006c369d3cea1d11f55</td>\n",
       "      <td>1717843333</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>0x25d963e67f5570cea9de9651111fd8466d27e598</td>\n",
       "      <td>1725511909</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>0xde3621b8ecd32273eb12f8b5bd1d5d7ea04b91b6</td>\n",
       "      <td>1703720689</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>0x3e415b89e5406c4d13717d434a2021ba97b4b5e7</td>\n",
       "      <td>1695810625</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>0x342ef1302087075aafc1bd11861c2797b98195ec</td>\n",
       "      <td>1695737200</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>0x29862218fdaf90a98b20a763b29b15a014375998</td>\n",
       "      <td>1717527664</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>0xff7afa1153c4d56756000b29ff534f309129ac26</td>\n",
       "      <td>1693863161</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152</td>\n",
       "      <td>0x2f1454a5bd2d9a2a7d9d9bfa21619cfbb1c5afbd</td>\n",
       "      <td>1716746189</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>0x8741dfe207d86fe8b50b5e0b7856dea9a2c13f2e</td>\n",
       "      <td>1702562544</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>0xa6262282f52626d4d5979aa5b8699f5599d1be81</td>\n",
       "      <td>1717552229</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>0xef32ef685baf8e42c2c7c6f639b18259029a0a84</td>\n",
       "      <td>1709303562</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>0x10e6ff88d235a93f2591ece84260ac177a4e7615</td>\n",
       "      <td>1711684287</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0x89046190320907bf2ce464e2480b709928d12b97</td>\n",
       "      <td>1715365132</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>0x0d1444f4284f17fe59199a86f93ecf85a483c85f</td>\n",
       "      <td>1719879457</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>0x018fb3c1e0138820f7a5ba2e300bdf39429e267c</td>\n",
       "      <td>1690788913</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>231</td>\n",
       "      <td>0x982b310c76b1a2ce40b59c328e7a24a21a4f59f1</td>\n",
       "      <td>1712479452</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>256</td>\n",
       "      <td>0x6ce26e33a23fac72499b8bafa405253be74acf16</td>\n",
       "      <td>1727247800</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>276</td>\n",
       "      <td>0x062ff50f82f9812627525e4ac0a0f4842b9e3c32</td>\n",
       "      <td>1703938986</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>280</td>\n",
       "      <td>0x16637ec9f50600eb89678a559286c7956d428703</td>\n",
       "      <td>1691153061</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>291</td>\n",
       "      <td>0x65be7f714c3d33096b4fa3ceece8c36fd124a302</td>\n",
       "      <td>1716701046</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>292</td>\n",
       "      <td>0x595ca03ef660bd929220ff8a31ae26ade0db5208</td>\n",
       "      <td>1712372406</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>0xd9c41e50ebe710f547fd98a0a0e86a581a77756d</td>\n",
       "      <td>1691328527</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>340</td>\n",
       "      <td>0x10c9801415296e99df2f291fa46f9a8412f913eb</td>\n",
       "      <td>1693648685</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>349</td>\n",
       "      <td>0xa835c40b10ca99a68a2de5a784403e64c1a0a6d4</td>\n",
       "      <td>1709131429</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>350</td>\n",
       "      <td>0xf103c84aa4f259314e2a8efbb9373ef37478c02e</td>\n",
       "      <td>1713453881</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>353</td>\n",
       "      <td>0x696cae8b10144f1c1a1fdb351c09bdfd08adf61d</td>\n",
       "      <td>1728222838</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>379</td>\n",
       "      <td>0x3076ce240d85fecdc7c6ac5817fccaa858a1bfb0</td>\n",
       "      <td>1724920210</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>393</td>\n",
       "      <td>0xef6b8f52e8469bc99252735e1e48a02fd380fd39</td>\n",
       "      <td>1733521022</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>394</td>\n",
       "      <td>0x65e2add58b53a83567fa9ed6b0c327d14cdfaa8a</td>\n",
       "      <td>1717669678</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>0x4a1e24d0aed6d7ac42486d389c822844b6cfc1f2</td>\n",
       "      <td>1733735303</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>0x3350f63c60378cc7084121e139532bd402d739ca</td>\n",
       "      <td>1712129236</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>424</td>\n",
       "      <td>0xb0bb1c49b47f2b21ddd8635d011b40b3ef95cbfc</td>\n",
       "      <td>1730774022</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>434</td>\n",
       "      <td>0x45427dfe57986b9440ba8f3a9e99e36bd0616fb3</td>\n",
       "      <td>1709816742</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>438</td>\n",
       "      <td>0x513983bacddef0d5c2ccaeccd544efe487d82556</td>\n",
       "      <td>1717348110</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>449</td>\n",
       "      <td>0x92cfe1a414c212583883487b10035b27c0f5feaa</td>\n",
       "      <td>1714385229</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>455</td>\n",
       "      <td>0x4a44c2719ef8d9d391c597862ece238aaf760689</td>\n",
       "      <td>1713743599</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>464</td>\n",
       "      <td>0xcef5ce921bb585743dabdd7324e2e41208203879</td>\n",
       "      <td>1703624618</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>472</td>\n",
       "      <td>0xd16deda244d16af4a9051046cd5291b203ada72a</td>\n",
       "      <td>1703185106</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>483</td>\n",
       "      <td>0x3bfcb4070bd28f06e3c1bd10f64255054ef0d9f6</td>\n",
       "      <td>1717245647</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>0x186b9d3a1b40f470379267151e9a002decaea8f1</td>\n",
       "      <td>1694185507</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0xdbe3f4adb6d632bf6b1bc3f7551c513722f9b7d6</td>\n",
       "      <td>1717547741</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>829</td>\n",
       "      <td>0x148dc183343f2ae99320dfb3ad32741743c997e5</td>\n",
       "      <td>1731448269</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>1655</td>\n",
       "      <td>0x651fbde5879fd38f31466f27513d9719dbefe852</td>\n",
       "      <td>1730964766</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                        user   timestamp  \\\n",
       "13       13  0x90eaa542a9575358b24bd7f5b8721989298c546a  1694019124   \n",
       "41       41  0x491919bcf7704fb4c328dd84affd2ad8eca5fd6a  1697124486   \n",
       "65       65  0x3f5282adca3b9bc02d385e539ad0e66ee7f65fce  1691929436   \n",
       "67       67  0x309a33959bd2cda19473110db175e6a8595cae4b  1701253162   \n",
       "77       77  0x111111cab58e134a2e3ecd8d3fb72488cf01fefa  1691318969   \n",
       "106     106  0xe964182ebe3aeb55fed219a07a6e3f38a59c1339  1692185020   \n",
       "110     110  0x54faad784c3addef84adecaa5ee30d3ed9abcf20  1717535235   \n",
       "112     112  0xa2a833e55401aab11ddf0006c369d3cea1d11f55  1717843333   \n",
       "114     114  0x25d963e67f5570cea9de9651111fd8466d27e598  1725511909   \n",
       "115     115  0xde3621b8ecd32273eb12f8b5bd1d5d7ea04b91b6  1703720689   \n",
       "120     120  0x3e415b89e5406c4d13717d434a2021ba97b4b5e7  1695810625   \n",
       "124     124  0x342ef1302087075aafc1bd11861c2797b98195ec  1695737200   \n",
       "134     134  0x29862218fdaf90a98b20a763b29b15a014375998  1717527664   \n",
       "144     144  0xff7afa1153c4d56756000b29ff534f309129ac26  1693863161   \n",
       "152     152  0x2f1454a5bd2d9a2a7d9d9bfa21619cfbb1c5afbd  1716746189   \n",
       "164     164  0x8741dfe207d86fe8b50b5e0b7856dea9a2c13f2e  1702562544   \n",
       "170     170  0xa6262282f52626d4d5979aa5b8699f5599d1be81  1717552229   \n",
       "178     178  0xef32ef685baf8e42c2c7c6f639b18259029a0a84  1709303562   \n",
       "193     193  0x10e6ff88d235a93f2591ece84260ac177a4e7615  1711684287   \n",
       "199     199  0x89046190320907bf2ce464e2480b709928d12b97  1715365132   \n",
       "223     223  0x0d1444f4284f17fe59199a86f93ecf85a483c85f  1719879457   \n",
       "226     226  0x018fb3c1e0138820f7a5ba2e300bdf39429e267c  1690788913   \n",
       "231     231  0x982b310c76b1a2ce40b59c328e7a24a21a4f59f1  1712479452   \n",
       "256     256  0x6ce26e33a23fac72499b8bafa405253be74acf16  1727247800   \n",
       "276     276  0x062ff50f82f9812627525e4ac0a0f4842b9e3c32  1703938986   \n",
       "280     280  0x16637ec9f50600eb89678a559286c7956d428703  1691153061   \n",
       "291     291  0x65be7f714c3d33096b4fa3ceece8c36fd124a302  1716701046   \n",
       "292     292  0x595ca03ef660bd929220ff8a31ae26ade0db5208  1712372406   \n",
       "298     298  0xd9c41e50ebe710f547fd98a0a0e86a581a77756d  1691328527   \n",
       "340     340  0x10c9801415296e99df2f291fa46f9a8412f913eb  1693648685   \n",
       "349     349  0xa835c40b10ca99a68a2de5a784403e64c1a0a6d4  1709131429   \n",
       "350     350  0xf103c84aa4f259314e2a8efbb9373ef37478c02e  1713453881   \n",
       "353     353  0x696cae8b10144f1c1a1fdb351c09bdfd08adf61d  1728222838   \n",
       "379     379  0x3076ce240d85fecdc7c6ac5817fccaa858a1bfb0  1724920210   \n",
       "393     393  0xef6b8f52e8469bc99252735e1e48a02fd380fd39  1733521022   \n",
       "394     394  0x65e2add58b53a83567fa9ed6b0c327d14cdfaa8a  1717669678   \n",
       "405     405  0x4a1e24d0aed6d7ac42486d389c822844b6cfc1f2  1733735303   \n",
       "407     407  0x3350f63c60378cc7084121e139532bd402d739ca  1712129236   \n",
       "424     424  0xb0bb1c49b47f2b21ddd8635d011b40b3ef95cbfc  1730774022   \n",
       "434     434  0x45427dfe57986b9440ba8f3a9e99e36bd0616fb3  1709816742   \n",
       "438     438  0x513983bacddef0d5c2ccaeccd544efe487d82556  1717348110   \n",
       "449     449  0x92cfe1a414c212583883487b10035b27c0f5feaa  1714385229   \n",
       "455     455  0x4a44c2719ef8d9d391c597862ece238aaf760689  1713743599   \n",
       "464     464  0xcef5ce921bb585743dabdd7324e2e41208203879  1703624618   \n",
       "472     472  0xd16deda244d16af4a9051046cd5291b203ada72a  1703185106   \n",
       "483     483  0x3bfcb4070bd28f06e3c1bd10f64255054ef0d9f6  1717245647   \n",
       "493     493  0x186b9d3a1b40f470379267151e9a002decaea8f1  1694185507   \n",
       "497     497  0xdbe3f4adb6d632bf6b1bc3f7551c513722f9b7d6  1717547741   \n",
       "829     829  0x148dc183343f2ae99320dfb3ad32741743c997e5  1731448269   \n",
       "1655   1655  0x651fbde5879fd38f31466f27513d9719dbefe852  1730964766   \n",
       "\n",
       "      history_count  history_span_seconds  \n",
       "13                5                     0  \n",
       "41                5                     0  \n",
       "65                5                     0  \n",
       "67                5                     0  \n",
       "77                5                     0  \n",
       "106               5                     0  \n",
       "110               5                     0  \n",
       "112               5                     0  \n",
       "114               5                     0  \n",
       "115               5                     0  \n",
       "120               5                     0  \n",
       "124               5                     0  \n",
       "134               5                     0  \n",
       "144               5                     0  \n",
       "152               5                     0  \n",
       "164               5                     0  \n",
       "170               5                     0  \n",
       "178               5                     0  \n",
       "193               5                     0  \n",
       "199               5                     0  \n",
       "223               5                     0  \n",
       "226               5                     0  \n",
       "231               5                     0  \n",
       "256               5                     0  \n",
       "276               5                     0  \n",
       "280               5                     0  \n",
       "291               5                     0  \n",
       "292               5                     0  \n",
       "298               5                     0  \n",
       "340               5                     0  \n",
       "349               5                     0  \n",
       "350               5                     0  \n",
       "353               5                     0  \n",
       "379               5                     0  \n",
       "393               5                     0  \n",
       "394               5                     0  \n",
       "405               5                     0  \n",
       "407               5                     0  \n",
       "424               5                     0  \n",
       "434               5                     0  \n",
       "438               5                     0  \n",
       "449               5                     0  \n",
       "455               5                     0  \n",
       "464               5                     0  \n",
       "472               5                     0  \n",
       "483               5                     0  \n",
       "493               5                     0  \n",
       "497               5                     0  \n",
       "829               5                     0  \n",
       "1655              8                     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sort_values(by=['history_count', 'history_span_seconds'], ascending=True).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d36438f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1039"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out[out['history_count'] < 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e56ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6985.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['history_count'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a876b3d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['grep', '^Total timestamps:', 'outputSpeedTest6.out', '-m', '10']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m     13\u001b[39m         \u001b[38;5;28mint\u001b[39m(match[\u001b[38;5;28mlen\u001b[39m(match_string) - \u001b[32m1\u001b[39m :])\n\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m subprocess.check_output(process, text=\u001b[38;5;28;01mTrue\u001b[39;00m).split(\n\u001b[32m     15\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m         )[:-\u001b[32m1\u001b[39m]\n\u001b[32m     17\u001b[39m     ]\n\u001b[32m     20\u001b[39m badOutputCounts = getTotalTimestamps(\u001b[33m\"\u001b[39m\u001b[33moutputSpeedTest4.out\u001b[39m\u001b[33m\"\u001b[39m, max_count=\u001b[32m10\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m goodOutputCounts = \u001b[43mgetTotalTimestamps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputSpeedTest6.out\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_count\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mgetTotalTimestamps\u001b[39m\u001b[34m(filename, max_count, reverse)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_count \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     11\u001b[39m     process += [\u001b[33m\"\u001b[39m\u001b[33m-m\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(max_count)]\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mint\u001b[39m(match[\u001b[38;5;28mlen\u001b[39m(match_string) - \u001b[32m1\u001b[39m :])\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.split(\n\u001b[32m     15\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m     )[:-\u001b[32m1\u001b[39m]\n\u001b[32m     17\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/finsur2/lib/python3.12/subprocess.py:466\u001b[39m, in \u001b[36mcheck_output\u001b[39m\u001b[34m(timeout, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    463\u001b[39m         empty = \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    464\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33minput\u001b[39m\u001b[33m'\u001b[39m] = empty\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m           \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.stdout\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/finsur2/lib/python3.12/subprocess.py:571\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     retcode = process.poll()\n\u001b[32m    570\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process.args,\n\u001b[32m    572\u001b[39m                                  output=stdout, stderr=stderr)\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process.args, retcode, stdout, stderr)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['grep', '^Total timestamps:', 'outputSpeedTest6.out', '-m', '10']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "def getTotalTimestamps(filename, max_count=None, reverse=False):\n",
    "    match_string = '^Total timestamps:'\n",
    "    if reverse:\n",
    "        process = [\"tac\", filename, \"|\", \"grep\", match_string]\n",
    "    else:\n",
    "        process = [\"grep\", match_string, filename]\n",
    "    if max_count is not None:\n",
    "        process += [\"-m\", str(max_count)]\n",
    "    return [\n",
    "        int(match[len(match_string) - 1 :])\n",
    "        for match in subprocess.check_output(process, text=True).split(\n",
    "            \"\\n\"\n",
    "        )[:-1]\n",
    "    ]\n",
    "\n",
    "\n",
    "badOutputCounts = getTotalTimestamps(\"outputSpeedTest4.out\", max_count=10)\n",
    "goodOutputCounts = getTotalTimestamps(\n",
    "    \"outputSpeedTest6.out\", max_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59e5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "badOutputCounts sum: 4468\n",
      "goodOutputCounts sum: 1202605\n",
      "ratio: 269.15957923008057\n"
     ]
    }
   ],
   "source": [
    "if len(goodOutputCounts) < len(badOutputCounts):\n",
    "    badOutputCounts = badOutputCounts[:len(goodOutputCounts)]\n",
    "badSum = sum(badOutputCounts)\n",
    "goodSum = sum(goodOutputCounts)\n",
    "print(f\"badOutputCounts sum: {badSum}\\ngoodOutputCounts sum: {goodSum}\")\n",
    "print(f\"ratio: {goodSum/badSum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dfa1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./Aave-Simulator/data/reserves/price_history.json\", \"r\") as file:\n",
    "    price_history = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ab37ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_history length: 7437460\n"
     ]
    }
   ],
   "source": [
    "print(f\"price_history length: {sum([len(prices) for prices in price_history.values()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888db4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_history keys: dict_keys(['DAI', 'USDC', 'WPOL', 'jEUR', 'WETH', 'LINK', 'GHST', 'USDT', 'WBTC', 'agEUR', 'CRV', 'BAL', 'EURS', 'DPI', 'SUSHI', 'miMATIC', 'MaticX', 'wstETH', 'AAVE', 'stMATIC'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"price_history keys: {price_history.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "917a3b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7437460"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTimestamps = [timestamp for timestamps_pairs in price_history.values() for timestamp in timestamps_pairs.keys()]\n",
    "len(allTimestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95742098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6011909"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueTimestamps = set(allTimestamps)\n",
    "len(uniqueTimestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42a7c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "\n",
    "def getSecondsTaken(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "    pattern = r\"^Name:([^\\n]+)\\nSeconds Taken:([^\\n]+)\"\n",
    "    matches = re.findall(pattern, text, re.MULTILINE)\n",
    "    names = set(name for name, _ in matches)\n",
    "    seconds_dict = {}\n",
    "    for name in names:\n",
    "        seconds_dict[name] = [float(seconds) for subName, seconds in matches if subName == name]\n",
    "    return seconds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36901ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_dict = getSecondsTaken(\"./speedTest31Output.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b45493d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max seconds taken for adaptive_granularity: 8.13046669960022\n",
      "Average seconds taken for adaptive_granularity: 0.6540547313818843\n",
      "Max seconds taken for event_driven: 104.71600556373596\n",
      "Average seconds taken for event_driven: 12.133959152244195\n",
      "Max seconds taken for binary_search: 6.102752447128296\n",
      "Average seconds taken for binary_search: 0.33750013115032124\n",
      "Max seconds taken for hybrid: 91.93166089057922\n",
      "Average seconds taken for hybrid: 10.228341040281583\n",
      "Max seconds taken for model_based: 0.752084493637085\n",
      "Average seconds taken for model_based: 0.060829215266853316\n",
      "Average seconds per group: 23.414684270324837\n"
     ]
    }
   ],
   "source": [
    "for name in seconds_dict.keys():\n",
    "    print(f\"Max seconds taken for {name}: {max(seconds_dict[name])}\")\n",
    "    print(f\"Average seconds taken for {name}: {sum(seconds_dict[name])/len(seconds_dict[name])}\")\n",
    "print(f\"Average seconds per group: {sum(sum(seconds_dict[name])/len(seconds_dict[name]) for name in seconds_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f8ecb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def getSecondsTaken(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "    pattern = r\"(\\d\\d\\d\\d-\\d\\d\\-\\d\\d \\d\\d:\\d\\d:\\d\\d,\\d\\d\\d) DEBUG Checkpoint 12$\"\n",
    "    matches = re.findall(pattern, text, re.MULTILINE)\n",
    "    timestamps = [datetime.strptime(date_string, \"%Y-%m-%d %H:%M:%S,%f\").timestamp() for date_string in matches]\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "320da8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = getSecondsTaken(\"./speedTest32.log\")\n",
    "# timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7d97f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total seconds to run: 35672.6210000515\n",
      "Total hours to run: 9.909061388903194\n",
      "Average seconds per test: 4.127342473684079\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total seconds to run: {timestamps[-1]-timestamps[0]}\")\n",
    "print(f\"Total hours to run: {(timestamps[-1]-timestamps[0])/60/60}\")\n",
    "print(f\"Average seconds per test: {(timestamps[-1]-timestamps[0])/(len(timestamps)-1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b421b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finsur2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
